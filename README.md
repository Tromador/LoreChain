# LoreChain

![Project Status](https://img.shields.io/badge/status-WIP-yellow)

By WIP I mean this readme is already at least somewhat wrong.

"Indentation-based syntax removes the freedom â€” and replaces it with fragility. Sure, it can look cleanâ€¦ but so does a plate of blancmange until you try to pick it up."
- ChatGPT talking about Python

**LangChain-based persistent memory layer for creative projects**  
Built for TTRPG lore, story development, and live session context retention â€” but adaptable to any domain where structured memory and semantic retrieval matter.

---

## ğŸ§  Why This Exists

Most LLM APIs â€” including OpenAI's â€” are stateless and short-term by design.  
When working with prewritten transcripts or running multi-hour sessions, youâ€™ll eventually hit context overflow and semantic drift.

**LoreChain addresses this** by:
- Persisting long-term memory across sessions
- Retrieving only whatâ€™s relevant via semantic search
- Allowing workflows that depend on continuity, world state, or structured recall

It works equally well for:
- ğŸ“œ TTRPG campaigns
- ğŸ›  Project logs and AARs
- ğŸ§¾ Multi-user shared knowledgebases
- ğŸ§‘â€ğŸ« Courseware or onboarding systems

---

## ğŸ§© Project Overview

**LoreChain** provides:

- ğŸ” A modular LangChain interface with vectorstore-based memory
- ğŸ§  Per-session context management using FAISS + HuggingFace embeddings
- ğŸ’¾ Disk persistence and session filtering support
- ğŸŒ API integration with OpenAI (via `langchain-openai`)
- ğŸ–¥ï¸ A lightweight Flask-based input UI for manual or automated entry

---

## ğŸš€ Requirements

- Python 3.10+ (tested in WSL Ubuntu)
- Working OpenAI API key (defined in config)
- A FAISS build compiled against **NumPy 2.x**
- Optionally: CUDA-enabled GPU for faster embedding

> This project was tested on a GPU-enabled system using large embedding models, but will run correctly on CPU with smaller models.  
> Embedding and vector search may be slower, but all functionality remains intact.

---

## âš ï¸ NumPy & FAISS Compatibility

> You **must** use a version of FAISS that is compatible with **NumPy 2.x**

LangChain now requires NumPy 2. Default FAISS builds from PyPI are compiled against NumPy 1.x.  
Mixing the two will result in segmentation faults or undefined behaviour.

### âœ… Solution

Build FAISS from source against NumPy 2.x with GPU enabled (if desired):

```bash
-DFAISS_ENABLE_GPU=ON
```

Do **not** downgrade NumPy â€” LangChain will break.

---

## âš™ï¸ GPU Acceleration (Optional)

If running on a CUDA-capable GPU, LoreChain supports:
- HuggingFace `bge-large-en-v1.5` embeddings (via `sentence-transformers`)
- FAISS-GPU for fast vector similarity
- Parallel processing alongside other tools like Whisper

> On an RTX 5090, typical usage (embedding + transcript processing) uses under 40% GPU load.  
> CPU fallback is supported, just slower. You can downsize the model if needed.

---

## ğŸ“ Project Structure

<details><summary><strong>Click to expand</strong></summary>

```
LoreChain/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ core.md
â”‚   â”œâ”€â”€ input_interface.md
â”‚   â””â”€â”€ memory.md
â”œâ”€â”€ lc_input_interface/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ langchain_relay.py
â”‚   â”œâ”€â”€ input_providers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ live.py
â”‚   â”‚   â””â”€â”€ manual.py
â”‚   â”œâ”€â”€ lc_core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bge_embedding.py
â”‚   â”‚   â”œâ”€â”€ chain_manager.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ config_sample.py
â”‚   â”‚   â”œâ”€â”€ memory_manager.py
â”‚   â”‚   â””â”€â”€ vectorstore/
â”‚   â”‚       â”œâ”€â”€ index.faiss
â”‚   â”‚       â””â”€â”€ index.pkl
â”‚   â”œâ”€â”€ lc_memory/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ memory_store.py
â”‚   â”‚   â””â”€â”€ session_manager.py
â”‚   â”œâ”€â”€ static/
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ input_form.html
```

</details>

---

## ğŸ’¬ Configuration

OpenAI API key and runtime parameters are defined in:

```python
# lc_core/config.py
OPENAI_API_KEY = "<your-key-here>"
```

This file is `.gitignore`d by default.

---

## âœ… Current Capabilities

| Module         | Status       | Notes                                       |
|----------------|--------------|---------------------------------------------|
| LangChain Core | âœ… Complete   | OpenAI + vectorstore memory                 |
| Memory Store   | âœ… Complete   | FAISS with per-session document tags        |
| Embeddings     | âœ… Complete   | HuggingFace BGE-large or custom model       |
| Input Web UI   | âœ… Working    | Manual and scripted input supported         |
| LlamaIndex     | ğŸš§ In Progress| Lore ingestion system (file-based preload)  |
| TTS / Output   | ğŸ§ª Prototype  | TTS pipeline under evaluation               |

---

## ğŸ“¢ Discord Input (Optional Integration)

You can optionally integrate LoreChain with the [**Discord-Transcription-Stack**](https://github.com/Tromador/Discord-Transcription-Stack), which captures diarised voice transcripts from Discord voice channels.

Currently, this stack uses Puppeteer to drive a ChatGPT session â€” but is designed to work with LoreChain via API relay in future revisions.

---

## âœ¨ Future Goals

- LlamaIndex-based lore ingestion and file management
- TTS (e.g. Bark, Coqui) for interactive playback
- Multi-user memory separation and switching
- Lore editing + AAR summarisation workflows

---

## ğŸ¤ Attribution

Built by [Tromador](https://github.com/Tromador), a game master and engineer solving real continuity problems with LLMs â€” not prompt games.

No hype. No marketing. Just real tools, running on real infrastructure.

[![License](https://img.shields.io/github/license/Tromador/LoreChain)](https://github.com/Tromador/LoreChain/blob/main/LICENSE)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/langchain-enabled-green)](https://github.com/hwchase17/langchain)
[![FAISS](https://img.shields.io/badge/FAISS-GPU--Optional-brightgreen)](https://github.com/facebookresearch/faiss)
[![Powered by OpenAI](https://img.shields.io/badge/powered%20by-OpenAI-000000?logo=openai&logoColor=white)](https://openai.com)
[![Hugging Face](https://img.shields.io/badge/embeddings-HuggingFace-orange?logo=huggingface&logoColor=white)](https://huggingface.co)

---

## ğŸ“œ License

BSD 3-Clause License â€” permissive use, **attribution required**.

---
